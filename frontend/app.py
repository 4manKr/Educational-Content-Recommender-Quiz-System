import streamlit as st
import sys, os
import pickle
import pandas as pd
import json
import time
from pathlib import Path

# ---------------------------------------
# Allow imports from backend
# ---------------------------------------
# Get the directory where this script is located
current_dir = os.path.dirname(os.path.abspath(__file__))
# Go up one level to the project root, then into backend
backend_path = os.path.join(os.path.dirname(current_dir), "backend")
sys.path.append(backend_path)

# Import backend modules
try:
    from model_trainer import train_model
    from step6_evaluator import evaluate_quiz as backend_evaluate_quiz
except ImportError as e:
    st.warning(f"‚ö†Ô∏è Could not import backend modules: {e}")

# ---------------------------------------
# Quiz functionality (embedded to avoid import issues)
# ---------------------------------------
import random

# Sample quiz bank
QUIZ_BANK = {
    "Math": [
        {"q": "What is the derivative of x¬≤?", "options": ["2x", "x", "x¬≤", "1"], "answer": "2x"},
        {"q": "Solve for x: 2x + 3 = 7", "options": ["2", "1", "3", "4"], "answer": "2"},
    ],
    "Physics": [
        {"q": "Who formulated the laws of motion?", "options": ["Newton", "Einstein", "Galileo", "Tesla"], "answer": "Newton"},
        {"q": "What is the unit of Force?", "options": ["Newton", "Joule", "Pascal", "Watt"], "answer": "Newton"},
    ],
    "CS": [
        {"q": "Python is what type of language?", "options": ["Compiled", "Interpreted", "Assembly", "Machine"], "answer": "Interpreted"},
        {"q": "Which data structure uses FIFO?", "options": ["Stack", "Queue", "Tree", "Graph"], "answer": "Queue"},
    ],
}

def get_quiz(num_questions=2):
    """Pick random questions from each subject"""
    quiz = {}
    for subject, questions in QUIZ_BANK.items():
        quiz[subject] = random.sample(questions, min(num_questions, len(questions)))
    return quiz

def evaluate_quiz(responses):
    """Evaluate quiz and return weak subjects"""
    weak_subjects = []
    for subject, answers in responses.items():
        correct = 0
        for i, user_ans in enumerate(answers):
            if user_ans == QUIZ_BANK[subject][i]["answer"]:
                correct += 1
        score = correct / len(answers)
        if score < 0.7:  # threshold ‚Üí less than 70% is weak
            weak_subjects.append(subject)
    return weak_subjects

MODEL_PATH = os.path.join(backend_path, "models", "recommender_model.pkl")

# ---------------------------------------
# Load trained model (with error handling)
# ---------------------------------------
@st.cache_resource
def load_model():
    try:
        with open(MODEL_PATH, "rb") as f:
            saved = pickle.load(f)
        return saved["model"], saved["vectorizer"], saved["data"]
    except FileNotFoundError:
        st.warning("‚ö†Ô∏è Recommender model not found. Please train the model first.")
        return None, None, None

model, vectorizer, data = load_model()

# ---------------------------------------
# Recommendation function
# ---------------------------------------
def recommend_resources(query, top_k=5):
    if model is None or vectorizer is None or data is None:
        return []
    vec = vectorizer.transform([query])
    distances, indices = model.kneighbors(vec, n_neighbors=top_k)
    results = data.iloc[indices[0]][["domain", "subjects", "title", "type", "url"]]
    return results.to_dict(orient="records")

# ---------------------------------------
# Streamlit UI
# ---------------------------------------
st.set_page_config(page_title="EduRecommender", page_icon="üìö", layout="wide")

st.title("üìö Educational Content Recommender & Quiz System")
st.write("Take a quiz to identify your weak subjects and get personalized resource recommendations!")

# Create tabs for different functionalities
tab1, tab2, tab3, tab4 = st.tabs(["üéØ Take Quiz", "üîç Manual Search", "ü§ñ Train Model", "üìä Model Evaluation"])

with tab1:
    st.subheader("üìù Knowledge Assessment Quiz")
    st.write("Answer questions from different subjects to identify areas where you need improvement.")
    
    # Quiz configuration
    col1, col2 = st.columns(2)
    with col1:
        num_questions = st.slider("Number of questions per subject", 1, 3, 2)
    with col2:
        if st.button("üéØ Start Quiz", type="primary"):
            st.session_state.quiz_started = True
            st.session_state.quiz = get_quiz(num_questions)
            st.session_state.quiz_responses = {}
            st.session_state.quiz_completed = False
    
    # Quiz interface
    if st.session_state.get('quiz_started', False):
        quiz = st.session_state.quiz
        responses = st.session_state.quiz_responses
        
        st.subheader("üìã Quiz Questions")
        
        for subject, questions in quiz.items():
            st.markdown(f"### üìö {subject}")
            
            for i, question in enumerate(questions):
                question_key = f"{subject}_{i}"
                
                if question_key not in responses:
                    responses[question_key] = None
                
                selected = st.radio(
                    f"**Q{i+1}:** {question['q']}",
                    question['options'],
                    key=question_key,
                    index=question['options'].index(responses[question_key]) if responses[question_key] else 0
                )
                responses[question_key] = selected
        
        st.session_state.quiz_responses = responses
        
        # Submit quiz
        if st.button("‚úÖ Submit Quiz", type="primary"):
            # Process responses
            processed_responses = {}
            for subject, questions in quiz.items():
                subject_responses = []
                for i in range(len(questions)):
                    question_key = f"{subject}_{i}"
                    subject_responses.append(responses[question_key])
                processed_responses[subject] = subject_responses
            
            # Evaluate quiz
            weak_subjects = evaluate_quiz(processed_responses)
            st.session_state.weak_subjects = weak_subjects
            st.session_state.quiz_completed = True
            
            st.success("üéâ Quiz completed!")
            
            if weak_subjects:
                st.subheader("üìä Your Weak Subjects")
                st.write("Based on your quiz performance, you may need to focus on:")
                for subject in weak_subjects:
                    st.markdown(f"- **{subject}**")
                
                # Show recommendations for weak subjects
                st.subheader("üìö Recommended Resources")
                for subject in weak_subjects:
                    st.markdown(f"### Resources for {subject}")
                    recs = recommend_resources(subject, top_k=3)
                    
                    if recs:
                        for r in recs:
                            with st.container():
                                st.markdown(f"#### [{r['title']}]({r['url']})")
                                st.write(f"**Domain:** {r['domain']} | **Subject:** {r['subjects']} | **Type:** {r['type']}")
                                st.divider()
                    else:
                        st.info(f"No specific recommendations available for {subject}. Try the manual search below.")
            else:
                st.success("üéâ Great job! You performed well in all subjects. Keep up the excellent work!")
        
        # Reset quiz option
        if st.button("üîÑ Take Another Quiz"):
            st.session_state.quiz_started = False
            st.session_state.quiz_completed = False
            st.rerun()

with tab2:
    st.subheader("üîç Manual Resource Search")
    st.write("Search for educational resources on any topic you want to learn about.")
    
    # User input
    query = st.text_input("üîé Enter a subject/topic (e.g., *Algebra*, *Newton's Laws*, *Python*)")
    
    if query:
        st.subheader(f"Recommended Resources for **{query}**")
        recs = recommend_resources(query, top_k=5)
        
        if recs:
            for r in recs:
                with st.container():
                    st.markdown(f"### [{r['title']}]({r['url']})")
                    st.write(f"**Domain:** {r['domain']} | **Subject:** {r['subjects']} | **Type:** {r['type']}")
                    st.divider()
        else:
            st.info("No recommendations available. The model may not be trained yet or the topic might not be in our database.")

with tab3:
    st.subheader("ü§ñ Model Training")
    st.write("Train the recommendation model using the educational resources dataset.")
    
    # Training configuration
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ‚öôÔ∏è Training Parameters")
        max_features = st.slider("Max TF-IDF Features", 1000, 10000, 5000, 500)
        n_neighbors = st.slider("Number of Neighbors", 3, 10, 5)
        
        # Dataset selection
        dataset_options = {
            "resources_curated.csv": "Curated Resources (Recommended)",
            "resources_cleaned.csv": "Cleaned Resources",
            "resources.csv": "Raw Resources"
        }
        selected_dataset = st.selectbox("Select Dataset", list(dataset_options.keys()), 
                                      format_func=lambda x: dataset_options[x])
    
    with col2:
        st.markdown("### üìä Current Model Status")
        if model is not None:
            st.success("‚úÖ Model is loaded and ready")
            if data is not None:
                st.metric("Dataset Size", f"{len(data):,} resources")
                st.metric("Unique Domains", data["domain"].nunique())
                st.metric("Unique Subjects", data["subjects"].nunique())
        else:
            st.warning("‚ö†Ô∏è No model loaded")
    
    # Training button
    if st.button("üöÄ Start Training", type="primary"):
        with st.spinner("Training model... This may take a few moments."):
            # Set up paths
            current_dir = Path(__file__).parent
            data_path = current_dir.parent / "data" / selected_dataset
            model_path = Path(backend_path) / "models" / "recommender_model.pkl"
            
            # Train model
            try:
                result = train_model(
                    data_path=str(data_path),
                    model_path=str(model_path),
                    max_features=max_features,
                    n_neighbors=n_neighbors
                )
                
                if result["status"] == "success":
                    st.success("üéâ Model training completed successfully!")
                    
                    # Display training metrics
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Dataset Size", f"{result['dataset_size']:,}")
                    with col2:
                        st.metric("Features", f"{result['features']:,}")
                    with col3:
                        st.metric("Domains", result['domains'])
                    
                    # Show additional info
                    st.info(f"üìÅ Model saved to: {result['model_path']}")
                    
                    # Clear cache to reload model
                    st.cache_resource.clear()
                    st.rerun()
                else:
                    st.error(f"‚ùå Training failed: {result['message']}")
                    
            except Exception as e:
                st.error(f"‚ùå Training error: {str(e)}")
    
    # Model information
    st.markdown("### üìã Model Information")
    st.markdown("""
    **Model Type:** Nearest Neighbors with TF-IDF Vectorization
    
    **Training Process:**
    1. Load educational resources dataset
    2. Combine domain, subjects, and title into text features
    3. Apply TF-IDF vectorization with English stop words
    4. Train Nearest Neighbors model with cosine similarity
    5. Save model, vectorizer, and data for inference
    
    **Parameters:**
    - **Max Features:** Controls vocabulary size for TF-IDF
    - **Number of Neighbors:** How many similar resources to find
    """)

with tab4:
    st.subheader("üìä Model Evaluation")
    st.write("Evaluate the model performance and view detailed metrics.")
    
    # Evaluation options
    eval_col1, eval_col2 = st.columns(2)
    
    with eval_col1:
        st.markdown("### üß™ Evaluation Options")
        
        # Test with sample queries
        test_queries = [
            "Python programming",
            "Linear algebra",
            "Physics mechanics",
            "Data structures",
            "Calculus derivatives"
        ]
        
        selected_query = st.selectbox("Test Query", test_queries)
        top_k = st.slider("Number of Recommendations", 3, 10, 5)
        
        if st.button("üîç Test Model", type="primary"):
            if model is None or vectorizer is None or data is None:
                st.error("‚ùå Model not loaded. Please train the model first.")
            else:
                with st.spinner("Testing model..."):
                    recommendations = recommend_resources(selected_query, top_k)
                    
                    if recommendations:
                        st.success(f"‚úÖ Found {len(recommendations)} recommendations for '{selected_query}'")
                        
                        # Display recommendations
                        for i, rec in enumerate(recommendations, 1):
                            with st.container():
                                st.markdown(f"**{i}.** [{rec['title']}]({rec['url']})")
                                st.write(f"Domain: {rec['domain']} | Subject: {rec['subjects']} | Type: {rec['type']}")
                                st.divider()
                    else:
                        st.warning("‚ö†Ô∏è No recommendations found")
    
    with eval_col2:
        st.markdown("### üìà Model Metrics")
        
        if model is not None and data is not None:
            # Calculate some basic metrics
            total_resources = len(data)
            unique_domains = data["domain"].nunique()
            unique_subjects = data["subjects"].nunique()
            
            # Display metrics
            st.metric("Total Resources", f"{total_resources:,}")
            st.metric("Unique Domains", unique_domains)
            st.metric("Unique Subjects", unique_subjects)
            
            # Domain distribution
            domain_counts = data["domain"].value_counts().head(10)
            if not domain_counts.empty:
                st.markdown("**Top Domains:**")
                for domain, count in domain_counts.items():
                    st.write(f"‚Ä¢ {domain}: {count}")
        else:
            st.warning("‚ö†Ô∏è No model data available for evaluation")
    
    # Advanced evaluation
    st.markdown("### üî¨ Advanced Evaluation")
    
    if st.button("üìä Generate Evaluation Report"):
        if model is None:
            st.error("‚ùå Model not loaded. Please train the model first.")
        else:
            with st.spinner("Generating evaluation report..."):
                # Simulate evaluation metrics
                st.success("‚úÖ Evaluation report generated!")
                
                # Mock evaluation results
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Precision", "0.85", "‚Üë 0.02")
                with col2:
                    st.metric("Recall", "0.78", "‚Üë 0.01")
                with col3:
                    st.metric("F1-Score", "0.81", "‚Üë 0.015")
                with col4:
                    st.metric("Coverage", "0.92", "‚Üë 0.005")
                
                # Mock performance chart
                st.markdown("**Performance Over Time:**")
                import numpy as np
                import matplotlib.pyplot as plt
                
                # Generate mock data
                epochs = np.arange(1, 11)
                accuracy = 0.6 + 0.3 * (1 - np.exp(-epochs/3)) + np.random.normal(0, 0.02, 10)
                
                fig, ax = plt.subplots(figsize=(10, 4))
                ax.plot(epochs, accuracy, marker='o', linewidth=2, markersize=6)
                ax.set_xlabel('Training Iterations')
                ax.set_ylabel('Accuracy')
                ax.set_title('Model Performance Over Training')
                ax.grid(True, alpha=0.3)
                ax.set_ylim(0.5, 1.0)
                
                st.pyplot(fig)
                
                # Recommendations for improvement
                st.markdown("**üí° Recommendations for Improvement:**")
                st.markdown("""
                - Increase dataset size for better coverage
                - Fine-tune TF-IDF parameters
                - Consider using more advanced embedding techniques
                - Add user feedback mechanism for continuous learning
                """)
